---
keywords: fastai
description: NDIR tech review
title: "[NDIR] (ENG) Hard-negative Mining for Mir-Flickr 1M Dataset"
toc: false
badges: false
comments: false
categories: [near-duplicate image detection, tech-review]
hide_{github,colab,binder,deepnote}_badge: true
nb_path: _notebooks/(eng)hard-negative-mining-for-mir-flickr-1m-dataset.ipynb
layout: notebook
---

<!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/(eng)hard-negative-mining-for-mir-flickr-1m-dataset.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="1.-Overview">1. Overview<a class="anchor-link" href="#1.-Overview"> </a></h1><p><strong>Hard-negative mining</strong> is one of <strong>sampling method</strong> that is usually used in object detection task. The hard-negative sample means <strong>difficult</strong> negative data like not high distance value but it is negative samples. Therefore, the hard-negative mining pick first hard-negative samples.<br><br></p>
<p>In near-duplicate image retrieval task, it means that the method firstly choose the hard-negative pair. As a representative example, following paper used this method.</p>
<blockquote><p>2019, Expert Systems and Applications, Lia Morra, "Benchmarking Unsupervised Near-Duplicate Image Detection"</p>
</blockquote>
<p>In above paper, they have to use Mir-Flickr 1M dataset which contain one million images. Generally, when we solve the ndir task by agglomeraive hierachical clustering algorithm, we have to use very big memory space, and also it takes at least $O(n^3)$ time complexity. Although we use parallel computing, that cannot be implemented. First of all, we can substitute clustering to binary classification task to solve clustering problem. If there are $n$ numbers of data, it can be $n \choose 2$ numbers of pair which can be classified to ND or NND. If that is ND, it can be 1, or not 0. Following paper used this method.</p>
<blockquote><p>2020, Mathematics, Zhili Zhou, "Near-Duplicate Image Detection System Using Coarse-to-Fine Matching Scheme Based on Global and Local CNN Features"</p>
</blockquote>
<p>In above method, we need to consider transivity property for each pairs. If there ise cluster which is classified ND, every elements satisfy transivity property in cluster. However, in binary classification problem,</p>
$$
\text{If} \,\ _{I_i} \text{ND}_{I_j} \,\ \text{and} \,\ _{I_j} \text{ND}_{I_k}, \,\ \text{then} \,\ 
$$<p>$(I_i, I_k)$ is not ND pair generally. In contrast, it is more general case, therefore we can consider it can be used.<br><br></p>
<p>What is left is the time complexity. The number of MFND dataset is 10e6 and the number of pairs is 4.999995e11. From now on, we will consider hard-negative mining algorithm to approximate score.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="2.-Hard-negative-mining-for-MFND-dataset">2. Hard-negative mining for MFND dataset<a class="anchor-link" href="#2.-Hard-negative-mining-for-MFND-dataset"> </a></h1><ul>
<li>Extract randomly selected query images and a compact set of NND from a large image collection that does not contain any near-duplicate match for each query image and element of collection.<ul>
<li>EX) Extract $K = 4400$ numbers of randomly selected query images and $M = 80000$ numbers of element to create a compact set from $1,000,000$ numbers of dataset.</li>
</ul>
</li>
<li>For each query image, we can compute distance with all of data in collection, and it will be $K \times M$ matrix.</li>
<li>For each row, extract NND pair which have minimum distance in that row. ($hn_1$)<ul>
<li>EX) $|hn_1| = 4400$</li>
</ul>
</li>
<li>For each sorted row, extract K-nearest neighbors from query image. ($hn_2$)    <ul>
<li>EX) $|hn_2| = 4400 \times 5$</li>
</ul>
</li>
</ul>
<blockquote><p>$hn_2$ is more "difficult" sample than $hn_1$.</p>
</blockquote>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Commnets">Commnets<a class="anchor-link" href="#Commnets"> </a></h1><ul>
<li>It seems like a good way to deal with really large datasets like MFND in parallel and in parallel. </li>
<li>This is a method of selecting a negative sample, and it should not be confused with selecting a sample that is well representative of the distribution.</li>
<li>It is a simple and good method, but it seems to be a bad method under the assumption that the concept of ND can be extended to IND and NIND. Expansion of this concept may define a new concept that can quantitatively evaluate the degree from Duplicate to NND.</li>
</ul>

</div>
</div>
</div>
</div>
 

