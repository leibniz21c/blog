---
keywords: fastai
description: Linear algebra summary note.
title: "[LinearAlgebra] CH02. Linear Transformation"
toc: false
badges: false
comments: false
categories: [linear-algebra]
hide_{github,colab,binder,deepnote}_badge: true
nb_path: _notebooks/ch02-linear-transformation.ipynb
layout: notebook
---

<!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/ch02-linear-transformation.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="2.0.-Elementary-Definitions-and-Theorems">2.0. Elementary Definitions and Theorems<a class="anchor-link" href="#2.0.-Elementary-Definitions-and-Theorems"> </a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h5 id="Definition.2.1.-Linear-Transformation">Definition.2.1. Linear Transformation<a class="anchor-link" href="#Definition.2.1.-Linear-Transformation"> </a></h5><p>$ \mathbb{K} $상의 벡터공간 $V$와 $W$에 대해서, 다음 두 조건을 만족하는 함수 $T \,\ : \,\ V \rightarrow W$를 linear transformation이라고 한다.
<br><br></p>
<p>$ ^\forall \mathbf{x}\mathbf{y} \in V, \,\ ^\forall \alpha \in \mathbb{K}, $<br></p>
<ol>
<li>$ T(\mathbf{x} + \mathbf{y}) = T(\mathbf{x}) + T(\mathbf{y}) $ </li>
<li>$ T(\alpha \mathbf{x}) = \alpha T(\mathbf{x}) $<br><br></li>
</ol>
<p>특히, 일차변환 $T \,\ : \,\ V \rightarrow W$가 전단사일때, 이를 linear isomorphism이라 한다. 그리고 이 때의 벡터공간 $V$와 $W$는 linear isomorphic이라고 하고, $ V \cong W $로 나타낸다.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>EX)</strong> <br></p>
<ul>
<li>Zero transformation</li>
<li>Identity transformation</li>
<li>Inverse transformation of linear transformation $ T $(Not always).</li>
<li>Matrix transformation</li>
</ul>
<p>$ \text{Let} \,\ A = [a_{ij}]_{m \times n} \,\ \text{for} \,\ a_{ij} \in \mathbb{K} $.<br>
$\text{If} \,\ ^\forall \mathbf{x} \in \mathbb{K}^n, \,\ T_A(\mathbf{x}) = A\mathbf{x} $,</p>
$$
T_A \,\ : \,\ \mathbb{K}^n \rightarrow \mathbb{K}^m
$$<ul>
<li>Differential transformation</li>
<li>Definite integral transformation</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="2.1.-Symmetric-Matrix-and-Orthogonal-Matrix">2.1. Symmetric Matrix and Orthogonal Matrix<a class="anchor-link" href="#2.1.-Symmetric-Matrix-and-Orthogonal-Matrix"> </a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h5 id="Definition.2.2.-Symmetric-Matrix-and-Orthogonal-Matrix">Definition.2.2. Symmetric Matrix and Orthogonal Matrix<a class="anchor-link" href="#Definition.2.2.-Symmetric-Matrix-and-Orthogonal-Matrix"> </a></h5>$$
\text{If} \,\ A^T = A \,\ \text{, then} \,\ A \,\ \text{is a symetric matrix.}
$$$$
\text{If} \,\ A^T = A^{-1} \,\ \text{, then} \,\ A \,\ \text{is an orthogonal matrix.}
$$
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h5 id="Theorem.2.1.">Theorem.2.1.<a class="anchor-link" href="#Theorem.2.1."> </a></h5><p>$\text{Let} \,\ Q_1 = [q_{ij}^{(1)}]_{n \times n} \,\ \text{and} \,\ Q_2 = [q_{ij}^{(2)}]_{n \times n}$.<br></p>
$$
\text{If} \,\ Q_1, \,\ Q_2 \,\ \text{are orthogonal matrices, then the followings are true.}
$$<ul>
<li>$ \text{Every pairs of columns are orthogonal.} $</li>
<li>$ \text{Every columns are unit vector.} $</li>
<li>$ Q_1Q_2 \,\ \text{is also orthogonal matrix.} $</li>
<li>$ |Q| = 1 \,\ \text{or} \,\ |Q| = -1 $</li>
</ul>
<p><strong>Proof.</strong> <br>
Trivial.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h5 id="Theorem.2.2.">Theorem.2.2.<a class="anchor-link" href="#Theorem.2.2."> </a></h5><p>$\text{Let} \,\ A \,\ \text{be a matrix.}$.<br></p>
$$
\text{Then,} \,\ A^TA \,\ \text{is a symmetric matrix.}
$$<ul>
<li>$ (i, i)\text{-element of} \,\ A^TA = A_{C_i}^TA_{C_i} \ge 0 $ </li>
</ul>
<p><strong>Proof.</strong> <br>
Trivial.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="2.2.-Eigenvalue-and-Eigenvector">2.2. Eigenvalue and Eigenvector<a class="anchor-link" href="#2.2.-Eigenvalue-and-Eigenvector"> </a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Consider $T_A \,\ : \,\ V \rightarrow V$ and following vector equation.</p>
$$
T_A(\mathbf{x}) = A\mathbf{x} = \lambda \mathbf{x} \quad \text{for} \,\ \lambda \in \mathbb{R}.
$$<p>$ \text{Since} \,\ (A - \lambda I_n)\mathbf{x} = \mathbf{0} \Leftrightarrow A\mathbf{x} = \lambda \mathbf{x}, $<br>
$ \text{by Basic Theorem of Algebra, above equation have} \,\ n \,\ \text{complex solutions in} \,\ V. $</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h5 id="Definition.2.3.-Eigenvalue-and-Eigenvector">Definition.2.3. Eigenvalue and Eigenvector<a class="anchor-link" href="#Definition.2.3.-Eigenvalue-and-Eigenvector"> </a></h5><p>$ \text{Let} \,\ T_A \,\ : \,\ V \rightarrow V \,\ \text{and} \,\ \text{correspond with matrix} \,\ A$.</p>
<ol>
<li>For $\lambda \in \mathbb{K}, \,\ T(\mathbf{x}) = \lambda \mathbf{x}$ is called <strong>characteristic equation of linear transform $T$</strong> .</li>
<li>In $T(\mathbf{x}) = \lambda \mathbf{x}$, $\lambda$ is called <strong>eigenvalue</strong>, and corresponding $\mathbf{x}(\neq \mathbf{0}, \in V)$ is called <strong>eigenvector</strong> .</li>
</ol>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h5 id="Theorem.2.3.">Theorem.2.3.<a class="anchor-link" href="#Theorem.2.3."> </a></h5><p>$n$차 정방행렬 A와 정칙행렬 $N$에 대해서 $A, A^T, N^{-1}AN$의 고유치는 일치한다.</p>
<p><strong>Proof.</strong> <br>
Trivial.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h5 id="Theorem.2.4.">Theorem.2.4.<a class="anchor-link" href="#Theorem.2.4."> </a></h5><p>$\text{Let} \,\ A = [a_{ij}]_{n \times n}.$<br></p>
$$
\begin{matrix} \prod_{k = 1}^{n} \lambda_k = |A| \\ \sum_{k = 1}^{n} \lambda_k = \sum_{k = 1}^{n} a_{kk} \end{matrix}
$$<p><strong>Proof.</strong> <br>
Trivial.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="2.3.-Diagonalization">2.3. Diagonalization<a class="anchor-link" href="#2.3.-Diagonalization"> </a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>유한차원 벡터공간 $V$의 일차변환 $T:V \rightarrow V$에 대해서, $T$의 행렬을 대각행렬로 만드는 $V$의 기저가 존재할까?</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>위의 문제는 <strong>theorem.2.3.</strong> 에 의해서 다음 문제와 동치이다.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>주어진 실정방행렬 $A$에 대해서, $N^{-1}AN$이 대각행렬이 되는 정칙행렬 $N$이 존재하는가? (복소정방행렬 $A$에 대해서는 $\bar{N}^{-1}AN$에 대해서 따진다.)</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h5 id="Definition.2.3.-Diagonalizable">Definition.2.3. Diagonalizable<a class="anchor-link" href="#Definition.2.3.-Diagonalizable"> </a></h5><p>$\text{Let} \,\ A = [a_{ij}]_{n \times n} \,\ \text{for} \,\ a_{ij} \in \mathbb{R}$. <br>
$\text{If} \,\ \exists \,\ \text{invertible matrix} \,\ N \in \mathbb{M}_{n \times n}(\mathbb{R}) \quad s.t. \quad N^{-1}AN = diag(d_1, d_2, \cdots, d_n),$<br>
$\text{then} \,\ A \,\ \text{is diagonalizable by} \,\ N$.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h5 id="Theorem.2.5.">Theorem.2.5.<a class="anchor-link" href="#Theorem.2.5."> </a></h5><p>$\text{Let} \,\ A = [a_{ij}]_{n \times n} \,\ \text{for} \,\ a_{ij} \in \mathbb{R}, \,\ \lambda_1, \lambda_2, \cdots, \lambda_n \,\ \text{are eigenvalues of matrix} \,\ A, \,\ \text{and} \,\ \mathbf{x}_1, \mathbf{x}_2, \cdots, \mathbf{x}_n \,\ \text{are corresponding eigenvectors of eigenvalues}$. <br>
$\text{Assume that} \,\ {\mathbf{x}_1, \mathbf{x}_2, \cdots, \mathbf{x}_n} \,\ \text{are ordered basis of} \,\ \mathbb{R}^n$.<br>
$\text{Let} \,\ N = [\mathbf{x}_1 \,\ \mathbf{x}_2 \,\ \cdots \,\ \mathbf{x}_n]$.<br>
$\text{Then} \,\ N \,\ \text{is invertible and} \,\ A \,\ \text{is diagonalizable by} \,\ N$.<br>
$\text{That is}$</p>
$$
N^{-1}AN = diag(\lambda_1, \lambda_2, \cdots, \lambda_n)
$$<p>.</p>
<ul>
<li>$ \text{If} \,\ \lambda_1, \lambda_2, \cdots, \lambda_n \,\ \text{are different with each other, then the eigenvectors} \,\ \mathbf{x}_1, \mathbf{x}_2, \cdots, \mathbf{x}_n \,\ \text{are linearly independent and diagonalizable.} $</li>
<li>$ \text{Eigenvector can be multiplied any scalar except zero.} $</li>
</ul>
<p><strong>Proof.</strong> <br>
Trivial.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h5 id="Theorem.2.6.">Theorem.2.6.<a class="anchor-link" href="#Theorem.2.6."> </a></h5><p>$\text{Let} \,\ A \,\ \text{be a diagonalizable real matrix.}$<br>
$\text{Then}$</p>
$$
A^k = N^{-1}D^kN \quad \text{for} \,\ k \in \mathbb{Z}.
$$<p><strong>Proof.</strong> <br>
Trivial.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>유한차원 내적공간 $V$의 일차변환 $T:V \rightarrow V$에 대해서, $T$의 행렬을 대각행렬로 만드는 $V$의 정규직교기저가 존재할까?</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>위의 문제는 <strong>theorem.2.3.</strong> 에 의해서 다음 문제와 동치이다.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>주어진 실정방행렬 $A$에 대해서, $P^{-1}AP$이 대각행렬이 되는 직교행렬 $P$가 존재하는가? (복소정방행렬 $A$에 대해서는 $\bar{P}^{-1}AP$에 대해서 따진다.)</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h5 id="Definition.2.4.-Orthogonally-Diagonalizable">Definition.2.4. Orthogonally Diagonalizable<a class="anchor-link" href="#Definition.2.4.-Orthogonally-Diagonalizable"> </a></h5><p>실정방행렬 $A$가 직교행렬 $P$에 의해서 대각화되면 A는 orthogonally diagonalizable이라고 한다.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h5 id="Theorem.2.7.">Theorem.2.7.<a class="anchor-link" href="#Theorem.2.7."> </a></h5><p>실대칭행렬 $A$에 대해서, 서로 다른 고유치에 대응되는 고유벡터는 직교한다.</p>
<p><strong>Proof.</strong> <br>
$ \text{Let} \,\ A \,\ \text{be orthogonally diagonalizable and} \,\ \lambda_1, \lambda_2, \cdots, \lambda_n, \mathbf{x}_1, \mathbf{x}_2, \cdots, \mathbf{x}_n \,\ \text{are eigenvalues and corresponding eigenvectors.} $<br>
$ \text{For} \,\ i \neq j, $<br>
$$
\begin{matrix}
\lambda_i \mathbf{x}_i^T \mathbf{x}_j &amp;= (A \mathbf{x}_i)^T \mathbf{x}_j \\
                                      &amp;= \mathbf{x}_i^T A^T \mathbf{x}_j \\
                                      &amp;= \mathbf{x}_i(A\mathbf{x}_j) \\
                                      &amp;= \mathbf{x}_i^T (\lambda_j \mathbf{x}_j)
\end{matrix}
$$</p>
<p>$ \text{Therefore,} \,\ (\lambda_i - \lambda_j)\mathbf{x}_i^T\mathbf{x}_j = 0. $<br>
$ \text{Since} \,\ \lambda_i - \lambda_j \neq 0, \mathbf{x}_i^T\mathbf{x}_j = 0.$</p>
<p>{% raw %}
$$ \therefore \quad \mathbf{x}_i \perp \mathbf{x}_j \,\ \text{for} \,\ i \neq j \quad \blacksquare$$
{% endraw %}</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h5 id="Theorem.2.8.">Theorem.2.8.<a class="anchor-link" href="#Theorem.2.8."> </a></h5><p>$n$차 실정방행렬 $A$에 대해서, $A$가 직교대각화가능일 필요충분조건은 $A$가 대칭행렬이다.</p>
<p><strong>Proof.</strong> <br>
Trivial.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="2.3.-Singular-Value-Decomposition">2.3. Singular Value Decomposition<a class="anchor-link" href="#2.3.-Singular-Value-Decomposition"> </a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h5 id="Definition.2.5.-Positive-Definite">Definition.2.5. Positive Definite<a class="anchor-link" href="#Definition.2.5.-Positive-Definite"> </a></h5><p>$ \text{Let} \,\ A \,\ \text{be a symmetric matrix.} $</p>
$$
\text{If} \,\ ^\forall \mathbf{x} \neq \mathbf{0}, \,\ \mathbf{x}^T A \mathbf{x} &gt; 0, \,\ \text{then} \,\ A \,\ \text{is called positive definite.}
$$$$
\text{If} \,\ ^\forall \mathbf{x} \neq \mathbf{0}, \,\ \mathbf{x}^T A \mathbf{x} \ge 0, \,\ \text{then} \,\ A \,\ \text{is called positive semidefinite.}
$$$$
\text{If} \,\ ^\forall \mathbf{x} \neq \mathbf{0}, \,\ \mathbf{x}^T A \mathbf{x} &lt; 0, \,\ \text{then} \,\ A \,\ \text{is called negative definite.}
$$$$
\text{If} \,\ ^\forall \mathbf{x} \neq \mathbf{0}, \,\ \mathbf{x}^T A \mathbf{x} \le 0, \,\ \text{then} \,\ A \,\ \text{is called negative semidefinite.}
$$
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h5 id="Theorem.2.9.">Theorem.2.9.<a class="anchor-link" href="#Theorem.2.9."> </a></h5><p>대칭행렬 $A$에 대하여 다음이 성립한다.</p>
<ul>
<li>$A$가 Positive definite면 모든 $A$의 모든 고윳값은 양수이다.</li>
<li>$A$가 Positive semidefinite면 모든 $A$의 모든 고윳값은 음이 아닌 수수이다.</li>
<li>$A$가 Negative definite면 모든 $A$의 모든 고윳값은 음수이다.</li>
<li>$A$가 Negative semidefinite면 모든 $A$의 모든 고윳값은 양이 아닌 실수이다.</li>
</ul>
<p><strong>Proof.</strong> <br>
Chapter03 이후</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h5 id="Application.2.1.-Eigenvalue-Decomposition(EVD)">Application.2.1. Eigenvalue Decomposition(EVD)<a class="anchor-link" href="#Application.2.1.-Eigenvalue-Decomposition(EVD)"> </a></h5>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>By above theorems.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h5 id="Application.2.2.-Singular-Value-Decomposition(SVD)">Application.2.2. Singular Value Decomposition(SVD)<a class="anchor-link" href="#Application.2.2.-Singular-Value-Decomposition(SVD)"> </a></h5>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Any matrix $A_{m \times n}$ can be decomposed as $ A = U_{m \times m} \Sigma_{m \times n} {V_{n \times n}}^T $<br>
where $ AA^T = U \Sigma \Sigma^T U^T, \,\ A^TA = V \Sigma^T \Sigma V^T $</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>

</div>
</div>
</div>
</div>
 

