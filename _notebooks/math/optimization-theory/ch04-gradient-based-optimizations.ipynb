{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "251fd9a4-0f29-4862-aa66-857c313e79aa",
   "metadata": {},
   "source": [
    "# \"[OptimizationTheory] CH04. Gradient based Optimizations\"\n",
    "> Optimization theory summary note.\n",
    "\n",
    "- toc: false\n",
    "- badges: false\n",
    "- comments: false\n",
    "- categories: [optimization-theory]\n",
    "- hide_{github,colab,binder,deepnote}_badge: true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1a44f0-4db4-4574-ae40-b586ca3fa045",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 4.1. Introduction\n",
    "Gradient descent is an iterative first-order optimisation algorithm used to find a local minimum of a given function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bfb94b-2506-4cd7-b5d7-6904d6933adc",
   "metadata": {},
   "source": [
    "#### 4.2. Gradient Descent\n",
    "\n",
    "##### Algorithm.4.1. Gradient Descent\n",
    "\n",
    "Gradient descent is an iterative method to find a stationary point of an unconstraint optimization problem : <br>\n",
    "$$\n",
    " \\theta^* = \\underset{\\mathbf{\\theta}} {\\arg\\min} L (\\mathbf{\\theta}) \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6526ec27-7f5d-464f-b9be-51180d2a64bc",
   "metadata": {},
   "source": [
    "$$\n",
    "L(\\mathbf{\\theta} + \\eta \\mathbf{d}) \\approx L(\\mathbf{\\theta}) + \\eta \\bigtriangledown  _\\mathbf{\\theta} ^ T L( \\mathbf{\\theta} ) \\mathbf{d} \\quad where \\quad \\eta > 0, \\,\\  \\left \\| \\mathbf{d}  \\right \\| = 1 \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f52d3c1-4abb-453a-9a78-886e228c84ea",
   "metadata": {},
   "source": [
    "$$\n",
    "L(\\mathbf{\\theta} + \\eta \\mathbf{d}) - L(\\mathbf{\\theta}) \\approx \\eta \\bigtriangledown  _\\mathbf{\\theta} ^ T L( \\mathbf{\\theta} ) \\mathbf{d} = \\eta \\cos{(\\phi)} \\left \\| \\bigtriangledown  _\\mathbf{\\theta} ^ T L( \\mathbf{\\theta} ) \\right \\| \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba058d0-59ab-49cb-a48f-910b495c7eb6",
   "metadata": {},
   "source": [
    "Find the directional vector $\\mathbf{d}$ that minimizes $ L(\\mathbf{\\theta} + \\eta \\mathbf{d} ) - L(\\mathbf{\\theta}) \\le 0 $\n",
    "\n",
    "$$\n",
    "\\cos{(\\phi)} = -1 \\,\\ \\rightarrow \\,\\ \\mathbf{d} = - \\frac{\\bigtriangledown_\\mathbf{\\theta} L( \\mathbf{\\theta} ) }{ \\left \\| \\bigtriangledown  _\\mathbf{\\theta} L( \\mathbf{\\theta} ) \\right \\| } \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbaadd9e-d7cd-4868-b2f9-9f3fcd57aed4",
   "metadata": {},
   "source": [
    "$$\n",
    "\\therefore \\mathbf{\\theta} + \\eta \\mathbf{d} = \\mathbf{\\theta} - \\eta \\frac{\\bigtriangledown_\\mathbf{\\theta} L( \\mathbf{\\theta} ) }{ \\left \\| \\bigtriangledown  _\\mathbf{\\theta} L( \\mathbf{\\theta} ) \\right \\| } = \\mathbf{\\theta} - \\alpha \\bigtriangledown_\\mathbf{\\theta} L( \\mathbf{\\theta} )\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117d0e83-a6a5-448d-9ee8-adac78297e6a",
   "metadata": {},
   "source": [
    "#### 4.3. 4 Types of Gradient Descent\n",
    "\n",
    "$ (i) \\,\\ \\text{Standard (or steepest) Gradient Descent} $\n",
    "$$ \\mathbf{w} \\leftarrow \\mathbf{w} - \\eta \\bigtriangledown \\mathbb{E}[J(\\mathbf{w})] $$\n",
    " - Practically infeasible\n",
    " - Thus, we need distribution about data $\\mathbf{x}$ (Contradiction)\n",
    " - So, We can use sample mean\n",
    "<br><br>\n",
    "\n",
    "$ (ii) \\,\\ \\text{Stochastic(online) Gradient Descent} $\n",
    "$$ \\mathbf{w} \\leftarrow \\mathbf{w} - \\eta \\bigtriangledown J_i(\\mathbf{w}) $$\n",
    " - Simple to implement \n",
    " - Effective for large-scale problem\n",
    " - Much less memory\n",
    " - Unstable(zigzaging)\n",
    " - Purpose : We just consider one of data\n",
    " - It can be convergent. But there is little unstable.\n",
    "<br><br>\n",
    "\n",
    "$ (iii) \\,\\ \\text{Batch gradient Descent} $\n",
    "$$ \\mathbf{w} \\leftarrow \\eta \\bigtriangledown \\sum_{i=1}^{N} J_i (\\mathbf{w}) $$\n",
    " - Accurate estimation of gradients\n",
    " - Parallelization of learning\n",
    " - Large memory\n",
    " - Big time-complexity can be problem in this method.(So slow)\n",
    " - But, there isn't problem in convergence. \n",
    " - Purpose : We consider all of data!\n",
    "<br><br>\n",
    "\n",
    "$ (vi) \\,\\ \\text{Mini-Batch Gradient Descent} $\n",
    "$$ \\mathbf{w} \\leftarrow \\mathbf{w} - \\eta \\bigtriangledown \\sum_{i \\in \\mathfrak{I}}^{N} J_i (\\mathbf{w}), \\quad 1 \\le \\left | \\mathfrak{I} \\right | \\le N $$\n",
    " - Most generalized version\n",
    " - Effective to deal with large\n",
    " - Amount of training data\n",
    " - Purpose : We just consider seveal datas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2993014f-5d27-45c6-af63-89857b972db5",
   "metadata": {},
   "source": [
    "#### 4.4. Newton's Method\n",
    "Newton's method is zero finding algorithm. Many equations can be solved by this algorithm and bisection search algorithm in numerical analysis. We use this method too because of gradient necessary condition, which is $\\nabla L = \\mathbf{0}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e8ead9-9b90-4d46-9fdf-779166e5636d",
   "metadata": {},
   "source": [
    "##### Algorithm.4.2. Newton-Rapson Method in Multivariate Function\n",
    "In gradient updating context, we can find hyperplane of $L$ at $\\mathbf{w}_0$\n",
    "\n",
    "$$\n",
    "\\mathbf{y} = \\nabla^2 L(\\mathbf{w})^T (\\mathbf{w} - \\mathbf{w}_0) + \\nabla L(\\mathbf{w}_0)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67232c9-9140-40e4-b0c6-8b81106b32e3",
   "metadata": {},
   "source": [
    "And we have to find next $\\mathbf{w}$ by obtaining solution of following eqation:\n",
    "\n",
    "$$\n",
    "\\nabla^2 L(\\mathbf{w})^T (\\mathbf{w} - \\mathbf{w}_0) + \\nabla L(\\mathbf{w}_0) = \\mathbf{0}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40e55b9-6a73-46f2-a5ec-3dbe791cf863",
   "metadata": {},
   "source": [
    "Therefore,\n",
    "\n",
    "$$\n",
    "\\mathbf{w}_1 = \\mathbf{w}_0 - H(\\mathbf{w}_0)^{-1} \\nabla L(\\mathbf{w}_0)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b579a71c-3298-4224-a52f-4b43d633cb6a",
   "metadata": {},
   "source": [
    "Actually, we can consider too polynomial approximation like Taylor series expansion. The result is surprising."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcbd2aa-c493-447f-b6e1-54331f86b3c0",
   "metadata": {},
   "source": [
    "$$\n",
    "L(\\mathbf{w} + \\Delta \\mathbf{w}) \\approx L(\\mathbf{w}) + \\nabla L (\\mathbf{w})^T \\Delta \\mathbf{w} + \\frac{1}{2} \\Delta \\mathbf{w}^T H(\\mathbf{w}) \\Delta \\mathbf{w}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590dad51-d759-43b0-b203-40cd4351e4e9",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial}{\\partial \\Delta \\mathbf{w}} L(\\mathbf{w} + \\Delta \\mathbf{w}) \\approx \\nabla L(\\mathbf{w}) + H(\\mathbf{w}) \\Delta \\mathbf{w} = \\mathbf{0}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1493cbc-c113-4426-89cc-c9c5a930e518",
   "metadata": {},
   "source": [
    "$$\n",
    "\\therefore \\,\\ \\Delta \\mathbf{w} = H(\\mathbf{w})^{-1} \\nabla L(\\mathbf{w})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a196709f-d736-4c7e-b939-57e403aaa623",
   "metadata": {},
   "source": [
    "The above result is the same as the result of the Newton Method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24464148-946a-4506-b524-4c535cf34c40",
   "metadata": {},
   "source": [
    "#### 4.4. Quasi-Newton Method\n",
    "The inverse of the Hessian matrix appearing in Newton's method is difficult to use because of its too much computation. By replacing this with an average gradient, the amount of computation can be reduced. Explore the BFGS method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02426de8-99d9-471f-b9d4-d918bd2cb2d1",
   "metadata": {},
   "source": [
    "#### 4.5. Update Rule with Momentum\n",
    "We can add a momentum term to the update equation to prevent slowing down of learning or reduce instability of learning. Basic update rule is following:\n",
    "\n",
    "$$\n",
    "\\mathbf{w}_{k + 1} = \\mathbf{w}_k - \\eta \\nabla_\\mathbf{w} L(\\mathbf{w}_k) + \\gamma \\mathbf{w}_{k - 1} \\,\\ \\text{for} \\,\\ k \\ge 2.\n",
    "$$\n",
    "\n",
    "There are various variants of the gradient update algorithm using momentum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc807c6-f9c9-46d5-9ad6-1d47f6b8740a",
   "metadata": {},
   "source": [
    "##### Algorithm.4.4. Nesterov Accelerated Gradient(NAG)\n",
    "When using Momentum, the direction of the gradient is also slightly shifted in the previous direction.\n",
    "\n",
    "$$\n",
    "\\mathbf{w}_{k + 1} = \\mathbf{w}_k - \\eta \\nabla_\\mathbf{w} L(\\mathbf{w}_k + \\gamma \\mathbf{w}_{k - 1}) + \\gamma \\mathbf{w}_{k - 1} \\,\\ \\text{for} \\,\\ k \\ge 2.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6827d1f3-326f-48c0-84bc-a97a6f898006",
   "metadata": {},
   "source": [
    "#### 4.6. Update Rule with Adaptive Leaning Rate\n",
    "If the learning rate is too small, the learning time is too long, and if the learning rate is too large, it diverges(zigzagging) and learning is not performed properly. <br>\n",
    "AdaGrad solves this problem through learning rate decay. However, this also has a problem (zero convergence problem), so the following methods are used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff25545-6cb8-4935-a85f-a466b7252611",
   "metadata": {},
   "source": [
    "##### Algorithm.4.5. Adaptive Gradient(AdaGrad)\n",
    "\n",
    "$$\n",
    "\\mathbf{w}_{k + 1} = \\mathbf{w}_k - \\frac{\\eta}{\\sqrt{\\epsilon + \\mathbf{d}_k}} \\odot \\nabla_\\mathbf{w} L(\\mathbf{w}_k), \\,\\ \\mathbf{d}_k = \\mathbf{d}_{k - 1} +  \\nabla_\\mathbf{w} L(\\mathbf{w}_k) \\odot \\nabla_\\mathbf{w} L(\\mathbf{w}_k)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e396130-c175-491f-835b-0481a3d1f5c6",
   "metadata": {},
   "source": [
    "The above algorithm has a fatal flaw. Since $d$ is infinitely increasing, the amount of change in the gradient will converge to zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9540879c-b0c6-4505-ab3e-a750dffcf894",
   "metadata": {},
   "source": [
    "##### Algorithm.4.6. Root Mean Square Propagation(RMSProp)\n",
    "\n",
    "$$\n",
    "\\mathbf{w}_{k + 1} = \\mathbf{w}_k - \\frac{\\eta}{\\sqrt{\\epsilon + \\mathbf{d}_k}} \\odot \\nabla_\\mathbf{w} L(\\mathbf{w}_k), \\,\\ \\mathbf{d}_k = \\gamma \\mathbf{d}_{k - 1} + (1 - \\gamma) \\nabla_\\mathbf{w} L(\\mathbf{w}_k) \\odot \\nabla_\\mathbf{w} L(\\mathbf{w}_k)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ac0082-330a-4378-a615-beed4cb6f1be",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Algorithm.4.7. Adaptive Delta(AdaDelta)\n",
    "\n",
    "$$\n",
    "\\mathbf{w}_{k + 1} = \\mathbf{w}_k - \\frac{\\sqrt{\\epsilon + \\mathbf{u}_k}}{\\sqrt{\\epsilon + \\mathbf{d}_k}} \\odot \\nabla_\\mathbf{w} L(\\mathbf{w}_k), \\,\\ \\mathbf{d}_k = \\gamma \\mathbf{d}_{k - 1} + (1 - \\gamma) \\nabla_\\mathbf{w} L(\\mathbf{w}_k) \\odot \\nabla_\\mathbf{w} L(\\mathbf{w}_k), \\,\\ \\mathbf{u}_k = \\gamma \\mathbf{u}_{k - 1} - (1 - \\gamma) \\frac{\\sqrt{\\epsilon + \\mathbf{u}_{k-1}}}{\\sqrt{\\epsilon + \\mathbf{d}_{k-1}}} \\odot \\nabla_\\mathbf{w} L(\\mathbf{w}_{k-1}) \\,\\ \\text{for} \\,\\ k \\ge 2.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7314351a-9559-44db-bdb6-bfc9de3f4ab5",
   "metadata": {},
   "source": [
    "#### 4.6. Hybrid Update Rule with Momentum and Adaptive Learning Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba47ffd-318c-4cec-ae36-cc992dfc38da",
   "metadata": {},
   "source": [
    "- Adaptive Moment Estimation(Adam) : Momentum + RMSProp\n",
    "- Nesterov-accelerated Adaptive Moment Estimation(NAdam) : NAG + Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc41de0b-b2bf-41a7-bf34-080ad554fd11",
   "metadata": {},
   "source": [
    "#### 4.7. Laerning Rate Scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d4b738-4916-44a6-b985-701f9556ad24",
   "metadata": {},
   "source": [
    "In implementations of neural network, the optimizer is important, but the learning rate scheduler is also important. In pytorch implementation, the followings are a commonly used learning rate scheduler."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf9e153-424c-44ae-b282-7319aac1730e",
   "metadata": {},
   "source": [
    "1. Constant Learning Rate\n",
    "2. LambdaLR\n",
    "\n",
    "```python\n",
    "scheduler = LambdaLR(optimizer, lr_lambda = lambda epoch: 0.95 ** epoch)\n",
    "```\n",
    "\n",
    "```python\n",
    "def func(epoch):\n",
    "    if epoch < 40:\n",
    "        return 0.5\n",
    "    elif epoch < 70:\n",
    "        return 0.5 ** 2\n",
    "    elif epoch < 90:\n",
    "        return 0.5 ** 3\n",
    "    else:\n",
    "        return 0.5 ** 4\n",
    "\n",
    "scheduler = LambdaLR(optimizer, lr_lambda = func\n",
    "```\n",
    "\n",
    "3. StepLR\n",
    "\n",
    "```python\n",
    "scheduler = StepLR(optimizer, step_size=200, gamma=0.5)\n",
    "```\n",
    "\n",
    "4. MultiStepLR\n",
    "\n",
    "```python\n",
    "scheduler = MultiStepLR(optimizer, milestones=[200, 350], gamma=0.5)\n",
    "```\n",
    "\n",
    "5. ExponentialLR\n",
    "\n",
    "```python\n",
    "scheduler = ExponentialLR(optimizer, gamma=0.95)\n",
    "```\n",
    "\n",
    "6. CosineAnnealingLR\n",
    "\n",
    "```python\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=100, eta_min=0.001)\n",
    "```\n",
    "\n",
    "7. CosineAnnealingWarmRestarts\n",
    "\n",
    "```python\n",
    "scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=50, T_mult=2, eta_min=0.001)\n",
    "```\n",
    "\n",
    "8. Custom CosineAnnealingWarmRestarts\n",
    "\n",
    "```python\n",
    "import math\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "\n",
    "class CosineAnnealingWarmUpRestarts(_LRScheduler):\n",
    "    def __init__(self, optimizer, T_0, T_mult=1, eta_max=0.1, T_up=0, gamma=1., last_epoch=-1):\n",
    "        if T_0 <= 0 or not isinstance(T_0, int):\n",
    "            raise ValueError(\"Expected positive integer T_0, but got {}\".format(T_0))\n",
    "        if T_mult < 1 or not isinstance(T_mult, int):\n",
    "            raise ValueError(\"Expected integer T_mult >= 1, but got {}\".format(T_mult))\n",
    "        if T_up < 0 or not isinstance(T_up, int):\n",
    "            raise ValueError(\"Expected positive integer T_up, but got {}\".format(T_up))\n",
    "        self.T_0 = T_0\n",
    "        self.T_mult = T_mult\n",
    "        self.base_eta_max = eta_max\n",
    "        self.eta_max = eta_max\n",
    "        self.T_up = T_up\n",
    "        self.T_i = T_0\n",
    "        self.gamma = gamma\n",
    "        self.cycle = 0\n",
    "        self.T_cur = last_epoch\n",
    "        super(CosineAnnealingWarmUpRestarts, self).__init__(optimizer, last_epoch)\n",
    "    \n",
    "    def get_lr(self):\n",
    "        if self.T_cur == -1:\n",
    "            return self.base_lrs\n",
    "        elif self.T_cur < self.T_up:\n",
    "            return [(self.eta_max - base_lr)*self.T_cur / self.T_up + base_lr for base_lr in self.base_lrs]\n",
    "        else:\n",
    "            return [base_lr + (self.eta_max - base_lr) * (1 + math.cos(math.pi * (self.T_cur-self.T_up) / (self.T_i - self.T_up))) / 2\n",
    "                    for base_lr in self.base_lrs]\n",
    "\n",
    "    def step(self, epoch=None):\n",
    "        if epoch is None:\n",
    "            epoch = self.last_epoch + 1\n",
    "            self.T_cur = self.T_cur + 1\n",
    "            if self.T_cur >= self.T_i:\n",
    "                self.cycle += 1\n",
    "                self.T_cur = self.T_cur - self.T_i\n",
    "                self.T_i = (self.T_i - self.T_up) * self.T_mult + self.T_up\n",
    "        else:\n",
    "            if epoch >= self.T_0:\n",
    "                if self.T_mult == 1:\n",
    "                    self.T_cur = epoch % self.T_0\n",
    "                    self.cycle = epoch // self.T_0\n",
    "                else:\n",
    "                    n = int(math.log((epoch / self.T_0 * (self.T_mult - 1) + 1), self.T_mult))\n",
    "                    self.cycle = n\n",
    "                    self.T_cur = epoch - self.T_0 * (self.T_mult ** n - 1) / (self.T_mult - 1)\n",
    "                    self.T_i = self.T_0 * self.T_mult ** (n)\n",
    "            else:\n",
    "                self.T_i = self.T_0\n",
    "                self.T_cur = epoch\n",
    "                \n",
    "        self.eta_max = self.base_eta_max * (self.gamma**self.cycle)\n",
    "        self.last_epoch = math.floor(epoch)\n",
    "        for param_group, lr in zip(self.optimizer.param_groups, self.get_lr()):\n",
    "            param_group['lr'] = lr\n",
    "            \n",
    "            \n",
    "optimizer = optim.Adam(model.parameters(), lr = 0)\n",
    "scheduler = CosineAnnealingWarmUpRestarts(optimizer, T_0=150, T_mult=1, eta_max=0.1,  T_up=10, gamma=0.5)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
